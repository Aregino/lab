# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {}
# META }

# MARKDOWN ********************

# # Perform data exploration for data science
# 
# Use the code in this notebook to perform data exploration for data science.!


# MARKDOWN ********************

# ### Carregar dados em um dataframe
# Agora voc√™ est√° pronto para executar o c√≥digo para obter dados. Voc√™ trabalhar√° com o [conjunto de dados Vendas de suco de laranja](https://learn.microsoft.com/en-us/azure/open-datasets/dataset-oj-sales-simulated?tabs=azureml-opendatasets?azure-portal=true) do Azure Open Datasets. Depois de carregar os dados, voc√™ converter√° os dados em um dataframe do Pandas, que √© a estrutura com suporte do Data Wrangler.
# 
# - [Executar o pr√©-processamento de dados com Data Wrangler no Microsoft Fabric](https://microsoftlearning.github.io/mslearn-fabric.pt-br/Instructions/Labs/08b-data-science-preprocess-data-wrangler.html)

# CELL ********************

# Azure storage access info for open dataset diabetes
blob_account_name = "azureopendatastorage"
blob_container_name = "ojsales-simulatedcontainer"
blob_relative_path = "oj_sales_data"
blob_sas_token = r"" # Blank since container is Anonymous access
    
# Set Spark config to access  blob storage
wasbs_path = f"wasbs://%s@%s.blob.core.windows.net/%s" % (blob_container_name, blob_account_name, blob_relative_path)
spark.conf.set("fs.azure.sas.%s.%s.blob.core.windows.net" % (blob_container_name, blob_account_name), blob_sas_token)
print("Remote blob path: " + wasbs_path)
    
# Spark reads csv
df = spark.read.csv(wasbs_path, header=True)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

import pandas as pd

df = df.toPandas()
df = df.sample(n=500, random_state=1)
    
df['WeekStarting'] = pd.to_datetime(df['WeekStarting'])
df['Quantity'] = df['Quantity'].astype('int')
df['Advert'] = df['Advert'].astype('int')
df['Price'] = df['Price'].astype('float')
df['Revenue'] = df['Revenue'].astype('float')
    
df = df.reset_index(drop=True)
df.head(4)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# #### **Exibir estat√≠sticas resumidas**
# 
# Agora que carregamos os dados, a pr√≥xima etapa √© pr√©-processar os dados usando o Data Wrangler. O pr√©-processamento √© uma etapa crucial em qualquer fluxo de trabalho de aprendizado de m√°quina. Ele envolve limpar os dados e transform√°-los em um formato que pode ser alimentado em um modelo de machine learning.
# 
# 1   Selecione Dados na faixa de op√ß√µes do notebook e, em seguida, selecione a lista suspensa Iniciar Data Wrangler.
# 
# 2   Selecione o conjunto de dados df. Quando o Data Wrangler √© iniciado, ele gera uma vis√£o geral descritiva do dataframe no painel Resumo.
# 
# 3   Selecione o recurso Receita e observe a distribui√ß√£o de dados desse recurso.
# 
# _Examine os detalhes do painel lateral Resumo e observe os valores das estat√≠sticas._
# 


# CELL ********************

# Code generated by Data Wrangler for pandas DataFrame

def clean_data(df):
    # Replace all instances of "." with "``" in column: 'Brand'
    df['Brand'] = df['Brand'].str.replace(".", "``", case=False, regex=False)
    # Capitalize the first character in column: 'Brand'
    df['Brand'] = df['Brand'].str.capitalize()
    return df

df_clean = clean_data(df.copy())
df_clean.head()

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

def clean_data(df):
    # Replace all instances of "." with " " in column: 'Brand'
    df['Brand'] = df['Brand'].str.replace(".", " ", case=False, regex=False)
    # Capitalize the first character in column: 'Brand'
    df['Brand'] = df['Brand'].str.title()
    return df
    
df = clean_data(df)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

df['Brand'].unique()

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ### **Aplicar transforma√ß√£o de codifica√ß√£o one-hot**
# 
# Agora, vamos gerar o c√≥digo para aplicar a transforma√ß√£o de codifica√ß√£o one-hot aos nossos dados como parte de nossas etapas de pr√©-processamento. Para tornar nosso cen√°rio mais pr√°tico, come√ßamos gerando alguns dados de exemplo. Isso nos permite simular uma situa√ß√£o do mundo real e nos fornece um recurso vi√°vel.

# MARKDOWN ********************

# Inicie o Data Wrangler no menu superior do dataframe df.
# 
# Selecione o recurso Brand na grade.
# 
# No painel Opera√ß√µes, expanda F√≥rmulas e, a seguir, selecione Codifica√ß√£o one-hot.
# 
# No painel Codifica√ß√£o one-hot, selecione Aplicar.
# 
# Navegue at√© o final da grade de exibi√ß√£o do Data Wrangler. Observe que ele adicionou tr√™s novos recursos (Brand_Dominicks, Brand_Minute Maid e Brand_Tropicana) e removeu o recurso Brand.

# CELL ********************

#Inicie o Data Wrangler no menu superior do dataframe df.

Selecione o recurso Brand na grade.

No painel Opera√ß√µes, expanda F√≥rmulas e, a seguir, selecione Codifica√ß√£o one-hot.

No painel Codifica√ß√£o one-hot, selecione Aplicar.

Navegue at√© o final da grade de exibi√ß√£o do Data Wrangler. Observe que ele adicionou tr√™s novos recursos (Brand_Dominicks, Brand_Minute Maid e Brand_Tropicana) e removeu o recurso Brand.

Saia do Data Wrangler sem gerar o c√≥digo.


# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# #### **Opera√ß√µes de classifica√ß√£o e filtro**
# 
# Imagine que precisamos examinar os dados de receita de um reposit√≥rio espec√≠fico e classificar os pre√ßos dos produtos. Nas etapas a seguir, usamos o Data Wrangler para filtrar e analisar o dataframe df.
# 
# Inicie o Data Wrangler para o dataframe df.
# 
# No painel Opera√ß√µes, expanda Classificar e filtrar.
# 
# Selecione Filtro.
# 
# No painel Filtro, adicione a seguinte condi√ß√£o:
# 
# - Coluna de destino: Store
# - Opera√ß√£o: Equal to
# - Valor: 1227
# - A√ß√£o: Keep matching rows
# 


# MARKDOWN ********************

# #### **Agrega√ß√£o de dados**
# 
# Suponha que precisamos entender a receita m√©dia gerada por cada marca. Nas etapas a seguir, usamos o Data Wrangler para executar um grupo por opera√ß√£o no dataframe df.
# 
# - Inicie o Data Wrangler para o dataframe df.
# - Volte ao painel Opera√ß√µes, selecione Agrupar por e agregar.
# - No painel Colunas a serem agrupadas por, selecione o recurso Brand.
# - Selecione Adicionar agrega√ß√£o.
# - Na propriedade Coluna a ser agregada, selecione o recurso Revenue.
# - Selecione Mean para a propriedade Tipo de Agrega√ß√£o.
# - Escolha Aplicar.
# - Selecione Copiar c√≥digo para a √°rea de transfer√™ncia.
# - Saia do Data Wrangler sem gerar o c√≥digo.
# 
# Combine o c√≥digo da transforma√ß√£o de vari√°vel Brand com o c√≥digo gerado pela etapa de agrega√ß√£o na fun√ß√£o clean_data(df). O bloco de c√≥digo final deve ser assim
# 
# 


# CELL ********************

# Code generated by Data Wrangler for pandas DataFrame

def clean_data(df):
    # Performed 1 aggregation grouped on column: 'Brand'
    df = df.groupby(['Brand']).agg(Revenue_mean=('Revenue', 'mean')).reset_index()
    return df

df_clean = clean_data(df.copy())
df_clean.head()

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

def clean_data(df):    
    # Replace all instances of "." with " " in column: 'Brand'    
    df['Brand'] = df['Brand'].str.replace(".", " ", case=False, regex=False)    
    # Capitalize the first character in column: 'Brand'    
    df['Brand'] = df['Brand'].str.title()
        
    # Performed 1 aggregation grouped on column: 'Brand'    
    df = df.groupby(['Brand']).agg(Revenue_mean=('Revenue', 'mean')).reset_index()    
        
    return df    
        
df = clean_data(df)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# # Codifica√ß√£o One-Hot
# 
# A **codifica√ß√£o one-hot (One-Hot Encoding)** √© uma t√©cnica usada para transformar vari√°veis categ√≥ricas em um formato num√©rico que pode ser utilizado em modelos de Machine Learning.
# 
# ## üìå O que √© One-Hot Encoding?
# 
# Muitos algoritmos de Machine Learning n√£o conseguem trabalhar diretamente com vari√°veis categ√≥ricas (como "Vermelho", "Azul", "Verde"), pois exigem dados num√©ricos. A codifica√ß√£o one-hot resolve isso criando uma nova coluna para cada categoria e atribuindo valores bin√°rios (0 ou 1) para indicar a presen√ßa daquela categoria.
# 
# ## üìä Exemplo Pr√°tico
# 
# ### üé® Vari√°vel Categ√≥rica Original:
# 
# | Cor |
# |------|
# | Azul |
# | Vermelho |
# | Verde |
# | Azul |
# | Verde |
# 
# ### üîÑ Ap√≥s One-Hot Encoding:
# 
# | Cor_Azul | Cor_Vermelho | Cor_Verde |
# |----------|-------------|-----------|
# | 1        | 0           | 0         |
# | 0        | 1           | 0         |
# | 0        | 0           | 1         |
# | 1        | 0           | 0         |
# | 0        | 0           | 1         |
# 
# Cada linha tem **1** na coluna correspondente √† categoria original e **0** nas demais.
# 
# ## üõ† Como Implementar no Python
# 
# Usando **pandas**:
# 
# ```python
# import pandas as pd
# 
# # Criando um DataFrame
# dados = pd.DataFrame({'Cor': ['Azul', 'Vermelho', 'Verde', 'Azul', 'Verde']})
# 
# # Aplicando One-Hot Encoding
# dados_one_hot = pd.get_dummies(dados, columns=['Cor'])
# 
# print(dados_one_hot)
# ```
# 
# ### üìå Resultado esperado:
# ```
#    Cor_Azul  Cor_Vermelho  Cor_Verde
# 0        1            0         0
# 1        0            1         0
# 2        0            0         1
# 3        1            0         0
# 4        0            0         1
# ```
# 
# ## ‚ö†Ô∏è Cuidados ao Usar One-Hot Encoding
# 
# üîπ **Explos√£o Dimensional**: Se a vari√°vel categ√≥rica tiver muitas categorias, o n√∫mero de colunas criadas pode ser muito grande, impactando a performance do modelo.
# 
# üîπ **Drop de uma Coluna**: Para evitar colinearidade, pode ser interessante remover uma das colunas geradas (usando `drop_first=True` no `pd.get_dummies()`).
# 
# üîπ **Sparse Matrices**: Para grandes datasets, utilizar representa√ß√µes esparsas pode economizar mem√≥ria.
# 
# ## üöÄ Conclus√£o
# 
# A codifica√ß√£o one-hot √© uma t√©cnica essencial para lidar com vari√°veis categ√≥ricas e torn√°-las utiliz√°veis por algoritmos de Machine Learning. No entanto, deve ser usada com cuidado para evitar problemas de explos√£o dimensional.

